<!DOCTYPE html>
<html>

<head>
    <title>TJBot-ASPHI SNAP</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" type="text/css" href="default.css">
</head>

<body>
    <p class="h0">SNAP! for TJBot documentation</p>

    <ol>
        <li>
            Connettere il TJBot ad uno schermo HDMI e accendere schermo e TJBot
        </li>
        <li>
            Aprire il browser web Chromium e, nella barra dei preferiti, cliccare sul link "TJBot Homepage"
        </li>
        <li>
            Selezionare l'icona "SNAP!" per raggiungere l'ambiente di programmazione visuale
        </li>
    </ol>

    <h1>Movimento</h1>
    <h2>Angolo del braccio</h2>
    <p>
        <img src="img/arm_angle.png" alt="Imposta angolo braccio ...">
        <br> Imposta il servo motore del braccio all'angolo specificato dal parametro numerico.
    </p>
    <p>
        <img src="img/wave.png" alt="Esempio di programma che utilizza il movimento del braccio">
        <br> Questo script di esempio dice al TJBot di muovere il braccio in alto e in basso per 5 volte, come se stesse
        salutando
        qualcuno.
    </p>

    <h1>Aspetto</h1>
    <h2>Colore del LED</h2>
    <p>
        <img src="img/led.png" alt="Imposta colore LED ...">
        <br> Accende il LED sulla testa del TJBot del colore specificato. Il parametro deve essere testuale e scritto in
        inglese
        (esempi: "green", "red", "blue", "yellow"). Il colore "black" causa lo spegnimento del LED.
    </p>
    <p>
        <img src="img/led_play.png" alt="Esempio di programma che utilizza il colore del LED">
        <br> In questo esempio, il LED si accende ripetutamente di un colore scelto a caso tra una lista di colori.
    </p>

    <h2>Conversation (Watson Assistant)</h2>
    <h3>Aggiungere un esempio ad una classe di parole o frasi</h3>
    <p>
        <img src="img/add_intent.png" alt="Aggiungere un esempio ad una classe di parole o frasi">
        <br> Le "classi" della conversation sono insiemi di parole o frasi che si riferiscono ad una medesima intenzione
        comunicativa
        (ad esempio "ciao", "buongiorno" e "buonasera" sono tutti modi per salutare). Con questo blocco è possibile
        aggiungere
        un esempio di parola o frase ad una classe.
    </p>

    <h3>Controllare che la conversazione sia pronta</h3>
    <p>
        <img src="img/conversation_status.png" alt="Controllare che la conversazione sia pronta">
        <br> Una volta aggiunto un esempio ad una classe, il servizio Watson Assistant ha bisogno di un po' di tempo per
        "allenarsi".
        Questo blocco ci dice se la conversazione è pronta o meno ad essere utilizzata restituendoci VERO o FALSO.
    </p>
    <h4>Esempio</h4>
    <p>
        <img src="img/conversation_status_example.png" alt="Esempio controllo status conversazione">
        <br> In questo esempio all'interno di un ciclo infinito "per sempre" viene ripetuto un controllo per cui se la
        conversazione
        risulta pronta il computer mi dice che è pronto, altrimenti mi dice che si sta allenando. Attende 2 secondi
        prima
        di controllare nuovamente. Il blocco "conversazione pronta" rappresenta quindi la "condizione" da mettere
        all'interno
        del blocco "se... allora... altrimenti...".
    </p>

    <h3>Riconoscere una classe in una parola o frase</h3>
    <p>
        <img src="img/check_intent.png" alt="Riconoscere una classe in una parola o frase">
        <br> Questo blocco ci dice VERO o FALSO a seconda che la parola o frase scritta nel secondo parametro (es.
        "buongiorno")
        venga riconosciuta dal Watson Assistant all'interno dell'insieme di parole o frasi (ovvero la "classe"
        precedentemente
        definita, nel nostro esempio "saluti") indicato nel primo parametro.
    </p>
    <h4>Esempio</h4>
    <p>
        <img src="img/check_intent_example_1.png" alt="">
        <br>
        <img src="img/check_intent_example_2.png" alt="">
        <br> In questo esempio viene inizialmente allenato il computer a riconoscere una classe chiamata "info-nome" con
        una
        serie di frasi di esempio che rappresentano modi in cui è possibile chiedere il nome ad un interlocutore.
        <br> Successivamente, premendo la barra spaziatrice sulla tastiera, il programma resta in attesa che la
        conversazione
        sia pronta. Solo in quel caso il programma procederà ad eseguire le istruzioni successive e dirà "Ciao!".
        <br> A quel punto rimarrà in ascolto per il riconoscimento vocale (il blocco "quello che sto ascoltando"). Se
        riconosce
        le parole capite come una frase appartenente alla classe "info-nome" allora risponde vocalmente dicendo il
        proprio
        nome, altrimenti comunica di non aver capito.
    </p>

    <h3>Azzerare le classi della conversazione</h3>
    <p>
        <img src="img/reset_conversation.png" alt="Azzerare le classi della conversazione">
        <br> Permette di azzerare tutte le classi e gli esempi creati.
        <br> ATTENZIONE: tutto il lavoro di addestramento del Watson Assistant precedentemente fatto verrà annullato.
    </p>

    <h3>Conversa con spazio di lavoro creato sul sito di Watson</h3>
    <p>
        <img src="img/converse.png" alt="Conversa con spazio di lavoro ...">
        <br> Invia una parola o frase, scritta come primo parametro (nel primo spazio vuoto), allo spazio di lavoro
        (workspace)
        il cui codice identificativo va copiato e incollato come secondo parametro. Questo blocchetto restituisce quindi
        la risposta elaborata dal Watson Assistant.
        <br> N.B. Il workspace deve appartenere al servizio le cui credenziali sono state inserite nei "settings" del
        TJBot,
        nel campo della Conversation (o Watson Assistant).
    </p>
    <p>
        <img src="img/written_conversation.png"
            alt="Esempio di ciclo per una conversazione scritta con Watson tramite SNAP">
        <br> In questo modo viene "chiesto" all'utente di inserire una frase su SNAP, la "risposta" dell'utente viene
        inviata
        alla conversazione di Watson, infine (grazie al blocchetto "dire") la sprite mostrerà un fumetto con la risposta
        ricevuta da Watson. Poi tutto si ripete.
    </p>

    <h1>Suono</h1>
    <h2>Text to Speech</h2>
    <p>
        <img src="img/speak.png" alt="Parla ... con voce ...">
        <br> Invia una parola o frase (primo parametro) al servizio di sintesi vocale di Watson, utilizzando la voce
        indicata
        nel secondo parametro.
    </p>
    <p>
        <img src="img/speak_example.png" alt="Esempio di utilizzo dei blocchi parla per il text to speech">
        <br> La voce default rappresenta la voce selezionata nei "settings" del TJBot. La voce deve essere scritta in
        questo
        formato: it-IT_FrancescaVoice, fr-FR_ReneeVoice e così via. Le voci disponibili sono elencate nella pagina dei
        "settings".
    </p>

    <h1>Sensori</h1>
    <h2>Speech to Text</h2>
    <p>
        <img src="img/listen.png" alt="Quello che sto ascoltando in lingua ...">
        <br>
        <p>
            Versione "microfono-browser":<br>
            questa modalità utilizza il riconoscimento vocale del browser web chromium, per tanto necessita di un tjbot
            connesso allo schermo (e non remoto) e di consentire al browser l'accesso al microfono (quando lo chiederà).
            ATTENZIONE: assicurarsi di aver selezionato il giusto microfono di input dall'icona a forma di telecamera
            nella parte desta della barra superiore del browser.
        </p>
        <p>
            Versione microfono tjbot:<br>
            questa modalità registra i suoni fino a che non percepisce 2 secondi di silenzio. Successivamente invia l'audio al servizio
            di Speech to Text di Watson e attende la risposta. La registrazione viene analizzata sulla base della lingua
            specificata nel parametro (ad esempio: "it" per italiano, "fr" per francese, "en" per inglese, "es" per spagnolo, e così
            via). Il parametro "default" sta ad indicare la lingua della voce selezionata nella pagina dei "settings" del TJBot.
            Infine, il blocchetto restituisce una parola o frase di testo scritto corrispondente a ciò che Watson è riuscito a
            riconoscere nei suoni registrati.
        </p>
    </p>
    <p>
        <img src="img/listen_example.png" alt="Esempio di utilizzo dello Speech to Text">
        <br> In questo esempio, il TJBot incita a dire qualcosa, poi registra la voce e salva le parole comprese in una
        variabile
        precedentemente creata. Infine il TJBot parla dicendo l'unione della frase "Ho capito..." e delle parole capite.
    </p>

    <h2>Visual Recognition</h2>
    <h3>Classificatore di default</h3>
    <p>
        <img src="img/visual_recognition.png" alt="Quello che sto vedendo">
        <br> Scatta una foto e la invia al servizio di Visual Recognition di Watson. Questa foto viene analizzata in
        base al
        "classificatore di default", ovvero secondo quello che Watson già conosce, senza bisogno che sia allenato in
        maniera
        specifica. Una volta ricevuta la risposta da Watson, questo blocco restituisce una o più parole corrispondenti
        alla
        descrizione dell'oggetto più saliente tra quelli riconosciuti nella foto.
    </p>
    <h3>Classificatore personalizzato</h3>
    <p>
        <img src="img/vrec_custom_classifier.png" alt="Quello che riconosco tra ... con soglia ...">
        <br> Scatta una foto e la invia al servizio di Visual Recognition. La foto viene analizzata sulla base del
        classificatore
        personalizzato addestrato dall'utente. Il codice del classificatore va indicato nel primo parametro. La soglia
        (secondo
        parametro) è invece un numero decimale compreso tra 0 e 1 che serve ad indicare con quale livello di "certezza"
        che
        Watson deve avere nel riconscimento di un oggetto affinché possa dare una risposta. Una soglia più alta fa sì
        che
        Watson fornisca risposte più attendibili, ma aumenta la probabilità che non abbia nessuna risposta da dare,
        oppure
        che abbia solamente risposte molto generiche. Una soglia più bassa garantisce risposte molto specifiche,
        tuttavia
        aumenta la probabilità degli errori.
    </p>

    <h1>Operatori</h1>
    <h2>Traduttore</h2>
    <p>
        <img src="img/translator.png" alt="Traduci ... da ... a ...">
        <br> Restituisce la traduzione della parola o frase scritta come primo parametro. Nel secondo parametro deve
        essere specificata
        la lingua di origine e nel terzo parametro la lingua di destinazione ("it", "fr, "es" e così via).
    </p>

    <h2>Tone Analyzer</h2>
    <p>
        <img src="img/tone_analyzer.png" alt="Tono di ...">
        <br> Questo blocco prende come parametro una parola o frase e la invia al servizio di Tone Analyzer di Watson.
        Quando
        riceve la risposta, restituisce una parola inglese che si riferisce alla emozione che con maggiore probabilità
        ha
        rilevato all'interno della frase inviata ("Joy", "Sadness", "Anger", "Surprise").
    </p>

    <h1>Progetti di esempio</h1>
    <h2>Interprete</h2>
    <p>
        <img src="img/interpreter.png" alt="Esempio di programma che fa comportare il TJBot come un interprete">
        <br> In questo esempio il TJBot si comporta come un interprete: prima registra le parole o le frasi pronunciate
        a voce
        e le trasforma in testo scritto, poi le traduce in una lingua diversa e le pronuncia grazie al Text to Speech
        (blocco
        "parla").
    </p>

    <h2>Emotions-Detector</h2>
    <p>
        <img src="img/emotions_detector.png" alt="Esempio di programma che fa comportare il TJBot come un interprete">
        <br> Il TJBot registra la voce, la traduce in testo e la analizza con il Tone Analyzer di Watson.
        Successivamente accende
        il LED sopra alla testa di un colore diverso in base alla emozione percepita.
    </p>

    <h2>Osservatore</h2>
    <p>
        <img src="img/observer.png" alt="Esempio di programma che utilizza la Visual Recognition">
        <br> Il TJBot invita a mostrargli qualcosa, aspetta un po', scatta una foto e la analizza con il servizio di
        Visual Recognition
        di Watson. Poi sintetizza vocalmente la descrizione dell'oggetto riconosciuto e la riproduce.
    </p>

</body>

</html>